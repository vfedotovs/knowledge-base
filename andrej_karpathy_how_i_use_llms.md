
https://www.youtube.com/watch?v=EWvNQjAaOHw&t=6234s


Chapters   
00:00:00 Intro into the growing LLM ecosystem   
00:02:54 ChatGPT interaction under the hood   
00:13:12 Basic LLM interactions examples   
00:18:03 Be aware of the model you're using, pricing tiers   
00:22:54 Thinking models and when to use them   
00:31:00 Tool use: internet search   
00:42:04 Tool use: deep research   
00:50:57 File uploads, adding documents to context   
00:59:00 Tool use: python interpreter, messiness of the ecosystem   
01:04:35 ChatGPT Advanced Data Analysis, figures, plots   
01:09:00 Claude Artifacts, apps, diagrams   
01:14:02 Cursor: Composer, writing code   
01:22:28 Audio (Speech) Input/Output   
01:27:37 Advanced Voice Mode aka true audio inside the model   
01:37:09 NotebookLM, podcast generation   
01:40:20 Image input, OCR   
01:47:02 Image output, DALL-E, Ideogram, etc.   
01:49:14 Video input, point and talk on app   
01:52:23 Video output, Sora, Veo 2, etc etc.   
01:53:29 ChatGPT memory, custom instructions   
01:58:38 Custom GPTs   
02:06:30 Summary   

Links    
OpenAI's ChatGPT https://chatgpt.com/   
Anthropic's Claude https://claude.ai/   
Google's Gemini https://gemini.google.com/   
xAI's Grok https://grok.com/   
Perplexity https://www.perplexity.ai/   
Google's NotebookLM https://notebooklm.google.com/   
Cursor https://www.cursor.com/   


The visualization UI I was using in the video: https://excalidraw.com/   
